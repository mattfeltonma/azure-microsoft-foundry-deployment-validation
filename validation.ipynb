{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd670df2",
   "metadata": {},
   "source": [
    "# Notebook setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684712f1",
   "metadata": {},
   "source": [
    "## Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3b52cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt --pre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b67942",
   "metadata": {},
   "source": [
    "## Setup logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b0a05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "def configure_logging(level=\"DEBUG\"):\n",
    "    \"\"\"This function configures logging for code being run based on the specified level.\n",
    "    Args:\n",
    "        level (str): The logging level to use (e.g., \"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\").\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Convert the level string to uppercase so it matches what the logging library expects\n",
    "        logging_level = getattr(logging, level.upper(), None)\n",
    "\n",
    "        # Setup a logging format\n",
    "        logging.basicConfig(\n",
    "            level=logging_level,\n",
    "            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "            handlers=[logging.StreamHandler(sys.stdout)]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to set up logging: {e}\", file=sys.stderr)\n",
    "        sys.exit(1) \n",
    "\n",
    "configure_logging(\"ERROR\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d300897c",
   "metadata": {},
   "source": [
    "## (OPTIONAL) Setup support for a proxy for inspection of calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5ed8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Setup proxy through local proxy; bypass proxy for metadata endpoint to avoid any issues with Microsoft authentication libraries\n",
    "os.environ[\"HTTP_PROXY\"] = \"http://127.0.0.1:8000\"\n",
    "os.environ[\"HTTPS_PROXY\"] = \"http://127.0.0.1:8000\"\n",
    "os.environ[\"NO_PROXY\"] = \"169.254.169.254\"\n",
    "\n",
    "# Add private CA root cert to trusted cert bundle for SDKs that use requests and httpx\n",
    "os.environ[\"REQUESTS_CA_BUNDLE\"] = \"/Users/someuser/Library/Preferences/httptoolkit/ca.pem\"\n",
    "os.environ[\"SSL_CERT_FILE\"] = \"/Users/someuser/Library/Preferences/httptoolkit/ca.pem\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dce8da",
   "metadata": {},
   "source": [
    "# V1 Agent Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9a5056",
   "metadata": {},
   "source": [
    "## Perform an inference using the responses API\n",
    "\n",
    "This will validate that the models are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3578d8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "load_dotenv(\".env\", override=True)\n",
    "\n",
    "project_client = AIProjectClient(\n",
    "    endpoint=os.environ[\"PROJECT_ENDPOINT\"],\n",
    "    credential=DefaultAzureCredential(),\n",
    ")\n",
    "\n",
    "with project_client.get_openai_client() as openai_client:\n",
    "    response = openai_client.responses.create(\n",
    "        model=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n",
    "        input=\"What is the size of France in square miles?\",\n",
    "    )\n",
    "    print(f\"Response output: {response.output_text}\")\n",
    "\n",
    "    response = openai_client.responses.create(\n",
    "        model=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n",
    "        input=\"And what is the capital city?\",\n",
    "        previous_response_id=response.id,\n",
    "    )\n",
    "    print(f\"Response output: {response.output_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab607a43",
   "metadata": {},
   "source": [
    "## Create, run, and delete a basic v1 agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1540a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.ai.agents import AgentsClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.agents.models import ListSortOrder\n",
    "\n",
    "load_dotenv(\".env\", override=True)\n",
    "\n",
    "agents_client = AgentsClient(\n",
    "    endpoint=os.environ[\"PROJECT_ENDPOINT\"],\n",
    "    credential=DefaultAzureCredential(),\n",
    ")\n",
    "\n",
    "with agents_client:\n",
    "    # Create agent\n",
    "    agent = agents_client.create_agent(\n",
    "        model=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n",
    "        name=\"writing-agent\",\n",
    "        instructions=\"You are a helpful writing assistant\"\n",
    "    )\n",
    "    print(f\"Created agent, agent ID: {agent.id}\")\n",
    "\n",
    "    # Create thread\n",
    "    thread = agents_client.threads.create()\n",
    "    print(f\"Created thread, thread ID: {thread.id}\")\n",
    "\n",
    "    # Create message\n",
    "    message = agents_client.messages.create(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=\"Write me a poem about flowers\"\n",
    "    )\n",
    "    print(f\"Created message, message ID: {message.id}\")\n",
    "\n",
    "    # Run agent and process\n",
    "    run = agents_client.runs.create_and_process(thread_id=thread.id, agent_id=agent.id)\n",
    "    \n",
    "    if run.status == \"failed\":\n",
    "        print(f\"Run failed: {run.last_error}\")\n",
    "    else:\n",
    "        # Get the last message from the agent\n",
    "        messages = agents_client.messages.list(thread_id=thread.id, order=ListSortOrder.ASCENDING)\n",
    "        for msg in messages:\n",
    "            if msg.text_messages:\n",
    "                last_text = msg.text_messages[-1]\n",
    "                print(f\"{msg.role}: {last_text.text.value}\")\n",
    "\n",
    "    # Cleanup\n",
    "    #agents_client.delete_agent(agent.id)\n",
    "    #print(\"Deleted agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab59bbc8",
   "metadata": {},
   "source": [
    "## Create and run a v1 agent that uses the file analysis tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e105e8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.ai.agents import AgentsClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.agents.models import ListSortOrder, FileSearchTool\n",
    "from openai import project\n",
    "\n",
    "load_dotenv(\".env\", override=True)\n",
    "\n",
    "agents_client = AgentsClient(\n",
    "    endpoint=os.environ[\"PROJECT_ENDPOINT\"],\n",
    "    credential=DefaultAzureCredential(),\n",
    ")\n",
    "\n",
    "# Upload file and create vector store\n",
    "file = agents_client.files.upload(file_path=\"./sample-files/product_info_1.md\", purpose=FilePurpose.AGENTS)\n",
    "vector_store = agents_client.vector_stores.create_and_poll(file_ids=[file.id], name=\"my_vectorstore\")\n",
    "\n",
    "# Create file search tool and agent\n",
    "# This tool will upload the file to the storage account then create an index for it in the AI Search instance\n",
    "file_search = FileSearchTool(vector_store_ids=[vector_store.id])\n",
    "agent = agents_client.create_agent(\n",
    "    model=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n",
    "    name=\"file-agent\",\n",
    "    instructions=\"You are a helpful assistant and can search information from uploaded files\",\n",
    "    tools=file_search.definitions,\n",
    "    tool_resources=file_search.resources,\n",
    ")\n",
    "\n",
    "# Create thread and process user message\n",
    "thread = agents_client.threads.create()\n",
    "agents_client.messages.create(thread_id=thread.id, role=\"user\", content=\"Hello, what Contoso products do you know?\")\n",
    "run = agents_client.runs.create_and_process(thread_id=thread.id, agent_id=agent.id)\n",
    "\n",
    "# Handle run status\n",
    "if run.status == \"failed\":\n",
    "    print(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "# Print thread messages\n",
    "messages = agents_client.messages.list(thread_id=thread.id, order=ListSortOrder.ASCENDING)\n",
    "for message in messages:\n",
    "    if message.run_id == run.id and message.text_messages:\n",
    "        print(f\"{message.role}: {message.text_messages[-1].text.value}\")\n",
    "\n",
    "# Cleanup resources\n",
    "agents_client.vector_stores.delete(vector_store.id)\n",
    "agents_client.files.delete(file_id=file.id)\n",
    "agents_client.delete_agent(agent.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea95a07",
   "metadata": {},
   "source": [
    "## Create and run an agent that uses a public MCP Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc1c550",
   "metadata": {},
   "source": [
    "### Find the tools advertised by the MCP Server\n",
    "\n",
    "Use the FastMCP library to get a list of tools available behind the MCP Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606fffff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from fastmcp import Client\n",
    "\n",
    "async def list_mcp_tools(server_url: str):\n",
    "    \"\"\"List tools available from an MCP server.\"\"\"\n",
    "    # Setup an async client to connect to the MCP server\n",
    "    async with Client(server_url) as client:\n",
    "        tools = await client.list_tools()\n",
    "        \n",
    "        # Write out each tool returned\n",
    "        print(f\"Found {len(tools)} tools:\")\n",
    "        for tool in tools:\n",
    "            print(f\"  - {tool.name}: {tool.description}\")\n",
    "\n",
    "await list_mcp_tools(\"https://learn.microsoft.com/api/mcp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca82bac6",
   "metadata": {},
   "source": [
    "### Run the agent and force call to the public MCP Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d057f44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from azure.ai.agents import AgentsClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.agents.models import (\n",
    "    ListSortOrder, \n",
    "    McpTool, \n",
    "    MCPToolResource,\n",
    "    ToolResources\n",
    ")\n",
    "from fastmcp.tools import tool\n",
    "\n",
    "load_dotenv(\".env\", override=True)\n",
    "\n",
    "# Create MCP tool for the Microsoft Learn MCP Server\n",
    "mcp_tool = McpTool(\n",
    "    server_label=\"ms_learn\",\n",
    "    server_url=\"https://learn.microsoft.com/api/mcp\",\n",
    "    allowed_tools=[\"microsoft_docs_search\"]\n",
    ")\n",
    "\n",
    "# Setup an AgentsClient\n",
    "agents_client = AgentsClient(\n",
    "    endpoint=os.environ[\"PROJECT_ENDPOINT\"],\n",
    "    credential=DefaultAzureCredential(),\n",
    ")\n",
    "\n",
    "with agents_client:\n",
    "    # Create agent with MCP tool\n",
    "    agent = agents_client.create_agent(\n",
    "        model=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n",
    "        name=\"mcp-agent\",\n",
    "        instructions=\"You are a helpful assistant who answers questions about Microsoft products using Microsoft Learn content. Use the available MCP tools to answer questions.\",\n",
    "        tools=mcp_tool.definitions,\n",
    "        tool_resources=mcp_tool.resources\n",
    "    )\n",
    "\n",
    "    # Create thread\n",
    "    thread = agents_client.threads.create()\n",
    "    print(f\"Created thread, thread ID: {thread.id}\")\n",
    "\n",
    "    # Create message\n",
    "    message = agents_client.messages.create(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=\"What is the largest SKU for an ExpressRoute Gateway?\"\n",
    "    )\n",
    "    print(f\"Created message, message ID: {message.id}\")\n",
    "\n",
    "    # Create run and poll for completion, handling tool approvals\n",
    "    run = agents_client.runs.create(\n",
    "        thread_id=thread.id, \n",
    "        agent_id=agent.id,\n",
    "        # Set the tool calls to be automatically approved\n",
    "        tool_resources=ToolResources(\n",
    "            mcp=[\n",
    "                MCPToolResource(\n",
    "                    server_label=\"ms_learn\",\n",
    "                    headers={},\n",
    "                    require_approval=\"never\"\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    print(f\"Created run, ID: {run.id}\")\n",
    "\n",
    "    while run.status in [\"queued\", \"in_progress\", \"requires_action\"]:\n",
    "        time.sleep(1)\n",
    "        run = agents_client.runs.get(thread_id=thread.id, run_id=run.id)\n",
    "\n",
    "        print(f\"Run status: {run.status}\")\n",
    "\n",
    "    if run.status == \"failed\":\n",
    "        print(f\"Run failed: {run.last_error}\")\n",
    "    else:\n",
    "        # Get messages\n",
    "        messages = agents_client.messages.list(thread_id=thread.id, order=ListSortOrder.ASCENDING)\n",
    "        print(\"\\nConversation:\")\n",
    "        print(\"-\" * 50)\n",
    "        for msg in messages:\n",
    "            if msg.text_messages:\n",
    "                last_text = msg.text_messages[-1]\n",
    "                print(f\"{msg.role}: {last_text.text.value}\")\n",
    "                print(\"-\" * 50)\n",
    "    \n",
    "    print(f\"Run completed with status: {run.status}\")\n",
    "    # Cleanup\n",
    "    agents_client.delete_agent(agent.id)\n",
    "    print(\"Deleted agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dfe32b",
   "metadata": {},
   "source": [
    "# V2 Agent Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e774e5",
   "metadata": {},
   "source": [
    "## Create, run, and delete a basic v2 agent\n",
    "This will validate that v2 agents can be created. This helps to validate a good chunk of the setup, including connectivity with the CosmosDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2223f960",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects.models import PromptAgentDefinition\n",
    "\n",
    "load_dotenv(\".env\", override=True)\n",
    "\n",
    "project_client = AIProjectClient(\n",
    "    endpoint=os.environ[\"PROJECT_ENDPOINT\"],\n",
    "    credential=DefaultAzureCredential(),\n",
    ")\n",
    "\n",
    "with project_client.get_openai_client() as openai_client:\n",
    "    agent = project_client.agents.create_version(\n",
    "        agent_name=\"basic-v2-agent\",\n",
    "        definition=PromptAgentDefinition(\n",
    "            model=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n",
    "            instructions=\"You are a helpful assistant that answers general questions\",\n",
    "        ),\n",
    "    )\n",
    "    print(f\"Agent created (id: {agent.id}, name: {agent.name}, version: {agent.version})\")\n",
    "\n",
    "    conversation = openai_client.conversations.create(\n",
    "        items=[{\"type\": \"message\", \"role\": \"user\", \"content\": \"What is the size of France in square miles?\"}],\n",
    "    )\n",
    "    print(f\"Created conversation with initial user message (id: {conversation.id})\")\n",
    "\n",
    "    response = openai_client.responses.create(\n",
    "        conversation=conversation.id,\n",
    "        extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "        input=\"\",\n",
    "    )\n",
    "    print(f\"Response output: {response.output_text}\")\n",
    "\n",
    "    openai_client.conversations.items.create(\n",
    "        conversation_id=conversation.id,\n",
    "        items=[{\"type\": \"message\", \"role\": \"user\", \"content\": \"And what is the capital city?\"}],\n",
    "    )\n",
    "    print(f\"Added a second user message to the conversation\")\n",
    "\n",
    "    response = openai_client.responses.create(\n",
    "        conversation=conversation.id,\n",
    "        extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "        input=\"\",\n",
    "    )\n",
    "    print(f\"Response output: {response.output_text}\")\n",
    "\n",
    "    openai_client.conversations.delete(conversation_id=conversation.id)\n",
    "    print(\"Conversation deleted\")\n",
    "\n",
    "project_client.agents.delete_version(agent_name=agent.name, agent_version=agent.version)\n",
    "print(\"Agent deleted\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
